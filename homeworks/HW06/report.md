# HW06 - Report

## 1. Dataset

Какой датасет выбран: `S06-hw-dataset-01.csv`  
Размер: (12000, 30) - 12 000 строк, 30 столбцов
Целевая переменная: `target` - бинарная классификация; доли классов: ~68% класс 0, ~32% класс 1 (умеренный дисбаланс)  
Признаки:  
- Числовые: `num01`-`num24` - 24 вещественных признака.  
- Категориальные-подобные: `cat_contract`, `cat_region`, `cat_payment`, `tenure_months` - целочисленные признаки с небольшим числом уникальных значений, интерпретируемые как категориальные или порядковые.

## 2. Protocol

Разбиение: train/test = 75%/25%, `random_state=42`, стратификация по `target` для сохранения пропорций классов.  
Подбор гиперпараметров: `GridSearchCV` на обучающей выборке с 5-кратной кросс-валидацией (`cv=5`), оптимизация по метрике **F1-score**, так как задача имеет умеренный дисбаланс классов.  
Финальная оценка качества выполнена **один раз** на тестовой выборке.  
Метрики:  
- **Accuracy** - доля правильных предсказаний.  
- **F1-score** - гармоническое среднее precision и recall; устойчива к дисбалансу.  
- **ROC-AUC** - площадь под ROC-кривой; оценивает способность модели разделять классы по вероятностям.

## 3. Models

Сравнивались следующие модели:

- **DummyClassifier** (`strategy="most_frequent"`) - наивный baseline, всегда предсказывает самый частый класс.
- **LogisticRegression** - линейная модель, обучалась через Pipeline со StandardScaler.
- **DecisionTreeClassifier** - одиночное дерево решений; подбирались `max_depth` и `min_samples_leaf`.
- **RandomForestClassifier** - ансамбль из 100 деревьев; подбирались `max_depth`, `min_samples_leaf`, `max_features`.
- **GradientBoostingClassifier** - последовательный boosting; подбирались `n_estimators`, `learning_rate`, `max_depth`.

Все модели обучались только на обучающих данных; тестовая выборка использовалась исключительно для финальной оценки.

## 4. Results

Финальные метрики на тестовой выборке:

| Модель               | Accuracy | F1      | ROC-AUC |
|----------------------|----------|---------|---------|
| Dummy                | 0.677    | 0.000   | -       |
| LogisticRegression   | 0.830    | 0.715   | 0.879   |
| DecisionTree         | 0.844    | 0.727   | 0.862   |
| RandomForest         | 0.914    | 0.856   | 0.963   |
| **GradientBoosting** | **0.926**|**0.880**|**0.969**|

**Победитель**: `GradientBoostingClassifier` - показал наилучшие результаты по всем трём метрикам. Особенно высокий ROC-AUC (0.969) указывает на отличное качество ранжирования объектов по вероятности принадлежности к положительному классу. Ансамбли значительно превосходят как наивный baseline, так и линейную модель.

## 5. Analysis

**Устойчивость**:  
GradientBoosting продемонстрировал стабильное поведение: высокие значения F1 и ROC-AUC говорят о хорошем балансе между precision и recall, а также надёжном разделении классов. Модель не переобучилась, несмотря на сложность.

**Ошибки**:  
Confusion matrix (сохранена в артефактах) показывает низкое число ошибок обоих типов. Высокий F1-score (0.88) означает, что модель эффективно находит представителей миноритарного класса без чрезмерного роста ложных срабатываний.

**Интерпретация**:  
Permutation importance (график сохранён) выявила ключевые признаки, такие как `num05`, `tenure_months`, `num12` и `cat_payment`. Это согласуется с ожиданиями: числовые признаки, участвовавшие в генерации сигнала, и поведенческие категориальные переменные оказывают наибольшее влияние на предсказание.

## 6. Conclusion

1. GradientBoostingClassifier оказался лучшей моделью для данного датасета, превзойдя даже RandomForest - что типично для boosting-методов на "чистых" синтетических данных.
2. Подбор гиперпараметров через кросс-валидацию позволил объективно сравнить модели и избежать случайного выбора параметров.
3. Использование F1-score для подбора и ROC-AUC для выбора финальной модели - разумная стратегия при наличии дисбаланса классов.
4. Все требования задания выполнены: есть baselines, три модели недели 6, подбор гиперпараметров, метрики, графики и артефакты.
5. Честный ML-протокол (разделение → подбор на train → оценка на test один раз) обеспечил достоверность результатов.
6. Результаты легко воспроизводимы благодаря фиксации `random_state=42`.